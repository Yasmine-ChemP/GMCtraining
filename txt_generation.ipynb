{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yasmine-ChemP/GMCtraining/blob/main/txt_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br-a9eGUNYZN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj_QqGPHN024",
        "outputId": "e26f0945-682d-440c-b424-74eeb4d756c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file= tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrP7kACKOSd9",
        "outputId": "61d0ccd4-5526-40ad-f0ba-b4e057f32415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/shakespeare.txt\n"
          ]
        }
      ],
      "source": [
        "print(path_to_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYj6KUcSOYi9",
        "outputId": "2c01b014-ffda-4b96-9045-36a842976049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "text=open(path_to_file, \"rb\").read().decode(encoding='utf-8')\n",
        "print(text[0:250])\n",
        "#length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBA2FFCwTIw-",
        "outputId": "27972ab1-a5cc-4e27-d941-250ece58addc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40001\n"
          ]
        }
      ],
      "source": [
        "print(len(text.split('\\n')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToDl0UJjRRXf",
        "outputId": "1cbe5950-4b4b-4ba4-dba7-b0cdb50e98d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "#the unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrKdPSGIV6Fj"
      },
      "outputs": [],
      "source": [
        "ids_from_chars= tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "\n",
        "def text_from_ids (ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
        "\n",
        "chars_from_ids= tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsbt5LoSX-rj",
        "outputId": "7477c3bd-5853-4add-dd26-1ad67ac111c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utLJrTzJY1CB",
        "outputId": "1daf355f-45ad-4613-9a72-d85747992d38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "ids_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8qxBWQGZaAv",
        "outputId": "6a2e746d-fc50-48bc-b736-0683cd828d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 : F\n",
            "48 : i\n",
            "57 : r\n",
            "58 : s\n",
            "59 : t\n",
            "2 :  \n",
            "16 : C\n",
            "48 : i\n",
            "59 : t\n",
            "48 : i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print('{} : {}'.format(ids,chars_from_ids(ids).numpy().decode('utf-8')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4ayUOhwZbPg",
        "outputId": "025c74e8-382d-47b4-bc51-2be53b82d9a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n",
            "now Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us ki\n",
            "ll him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be d\n",
            "one: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citi\n"
          ]
        }
      ],
      "source": [
        "#chaque exemple aura son x qui represent 10 caracteres , et le y qui represente les 100 prochainss caracteres \n",
        "\n",
        "seq_length = 100\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOeINQlXbT0C",
        "outputId": "32854143-b343-49ac-9546-8a8e89d7ba1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#On va générer à partir de chaque exemple un input (x) et un label (y), en sachat que y représente le prochain caractére après x\n",
        "#exemple\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyUDbvwnb0eQ"
      },
      "outputs": [],
      "source": [
        "#Notre corpus a été traité et maintenant nous avons un dataset\n",
        "#avec l'input et le label correspondant.\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JvsVyNkb_Vg",
        "outputId": "3247ebc6-73fa-45a7-8a0d-ac628f336a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "Target: irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "-------------------------------------------------------------\n",
            "Input : are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "Target: re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n",
            "-------------------------------------------------------------\n",
            "Input : now Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us k\n",
            "Target: ow Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us ki\n",
            "-------------------------------------------------------------\n",
            "Input : ll him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be \n",
            "Target: l him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be d\n",
            "-------------------------------------------------------------\n",
            "Input : one: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor cit\n",
            "Target: ne: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citi\n",
            "-------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(5):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy().decode('utf-8'))\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy().decode('utf-8'))\n",
        "    print('-------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaJrKokAclKm"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.shuffle(1000).batch(32,drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKAEye9sdL1V",
        "outputId": "c8e6cb77-ccfa-4a76-ec29-6c49e26631b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ],
      "source": [
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5Mqs1zeenWM"
      },
      "outputs": [],
      "source": [
        "class text_generator(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "model = text_generator(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDmbb6u7gyIs",
        "outputId": "098fe3b5-2850-407b-d89c-d9190cbdcdc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 66) # (batch_size, sequence_length, vocab_size)\n",
            "tf.Tensor(\n",
            "[[-1.58620952e-03 -8.99900869e-03 -2.95061478e-03 ... -3.41817294e-03\n",
            "  -7.65823806e-03  5.20007452e-05]\n",
            " [ 1.07349325e-02 -7.77952699e-03 -1.33121377e-02 ...  1.90391354e-02\n",
            "  -6.85085426e-04 -7.31240259e-03]\n",
            " [ 1.72874816e-02 -4.24209330e-03 -1.88576393e-02 ...  2.96124835e-02\n",
            "   2.87965825e-03 -1.28748771e-02]\n",
            " ...\n",
            " [-2.68900907e-03  8.39425344e-03 -8.42684414e-04 ... -1.69341289e-03\n",
            "  -1.08202994e-02  1.80203393e-02]\n",
            " [-2.49829376e-03 -4.31051245e-03  2.66899494e-03 ...  1.02829784e-02\n",
            "   1.40545852e-02 -4.36308514e-03]\n",
            " [-1.48637388e-02 -9.44947265e-03 -3.83418170e-04 ...  3.59617546e-03\n",
            "   1.63448602e-02 -6.72300067e-03]], shape=(100, 66), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "    print(example_batch_predictions[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP0Kka0mhVAA"
      },
      "outputs": [],
      "source": [
        "#à chaque timestamp (caractère) on obtient la prédiction du prochain caractére\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA0dBS-ghVvt",
        "outputId": "d3fd7c69-c825-4af3-fef3-d66514886e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " !\n",
            "\n",
            "VOLUMNIA:\n",
            "One on 's father's moods.\n",
            "\n",
            "VALERIA:\n",
            "Indeed, la, 'tis a noble child.\n",
            "\n",
            "VIRGILIA:\n",
            "A crack,\n",
            "\n",
            "Next Char Predictions:\n",
            " ZmA;zaDk?sCYngzXUt:Ty,ulYw&\n",
            "dyVqfFLpe$ .?Stl'UdylCGLItTvFcBwulcXuyXcpwsZNXKD.Q! I'bFODCFAY!YydCxdvlL\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy().decode('utf-8'))\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa4-nYvjiGj-",
        "outputId": "85864af9-e9b0-4894-bab6-bb65e571c0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (32, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1899853, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "#On passe à de l'apprentissage.\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CbeA9T7iIOe",
        "outputId": "9500c693-cc01-4729-c345-130098afc189"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.02182"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d49nROcgiO1O"
      },
      "outputs": [],
      "source": [
        "#configuration du model\n",
        "model.compile(optimizer='adam', loss=loss , metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o9RiB0fjAHE"
      },
      "outputs": [],
      "source": [
        "#Configuration du modèle.\n",
        "model.compile(optimizer='adam', loss=loss,metrics=['accuracy'])\n",
        "# On peut enregistrer l'apprentissage de notre modèle en réalisant des checkpoints\n",
        "# Cela nous permettra de pouvoir résumer l'apprentissage à un temps voulu\n",
        "# Ou même de revenir en arriére.\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBJb4j8mj3Pr",
        "outputId": "f3a18d34-891f-4e05-991a-39b3b334db81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 2.3679 - accuracy: 0.3473\n",
            "Epoch 1: saving model to ./training_checkpoints/ckpt_1\n",
            "345/345 [==============================] - 16s 34ms/step - loss: 2.3665 - accuracy: 0.3475\n",
            "Epoch 2/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.7080 - accuracy: 0.4939\n",
            "Epoch 2: saving model to ./training_checkpoints/ckpt_2\n",
            "345/345 [==============================] - 11s 32ms/step - loss: 1.7080 - accuracy: 0.4939\n",
            "Epoch 3/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.4969 - accuracy: 0.5489\n",
            "Epoch 3: saving model to ./training_checkpoints/ckpt_3\n",
            "345/345 [==============================] - 11s 32ms/step - loss: 1.4969 - accuracy: 0.5489\n",
            "Epoch 4/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 1.3899 - accuracy: 0.5760\n",
            "Epoch 4: saving model to ./training_checkpoints/ckpt_4\n",
            "345/345 [==============================] - 13s 37ms/step - loss: 1.3899 - accuracy: 0.5760\n",
            "Epoch 5/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 1.3204 - accuracy: 0.5935\n",
            "Epoch 5: saving model to ./training_checkpoints/ckpt_5\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 1.3204 - accuracy: 0.5935\n",
            "Epoch 6/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.2638 - accuracy: 0.6074\n",
            "Epoch 6: saving model to ./training_checkpoints/ckpt_6\n",
            "345/345 [==============================] - 11s 33ms/step - loss: 1.2638 - accuracy: 0.6074\n",
            "Epoch 7/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 1.2120 - accuracy: 0.6218\n",
            "Epoch 7: saving model to ./training_checkpoints/ckpt_7\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 1.2121 - accuracy: 0.6217\n",
            "Epoch 8/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.1614 - accuracy: 0.6357\n",
            "Epoch 8: saving model to ./training_checkpoints/ckpt_8\n",
            "345/345 [==============================] - 11s 33ms/step - loss: 1.1614 - accuracy: 0.6357\n",
            "Epoch 9/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.1069 - accuracy: 0.6509\n",
            "Epoch 9: saving model to ./training_checkpoints/ckpt_9\n",
            "345/345 [==============================] - 12s 33ms/step - loss: 1.1069 - accuracy: 0.6509\n",
            "Epoch 10/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.0526 - accuracy: 0.6670\n",
            "Epoch 10: saving model to ./training_checkpoints/ckpt_10\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 1.0526 - accuracy: 0.6670\n",
            "Epoch 11/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9943 - accuracy: 0.6840\n",
            "Epoch 11: saving model to ./training_checkpoints/ckpt_11\n",
            "345/345 [==============================] - 12s 33ms/step - loss: 0.9943 - accuracy: 0.6840\n",
            "Epoch 12/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9364 - accuracy: 0.7018\n",
            "Epoch 12: saving model to ./training_checkpoints/ckpt_12\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.9364 - accuracy: 0.7018\n",
            "Epoch 13/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.8825 - accuracy: 0.7189\n",
            "Epoch 13: saving model to ./training_checkpoints/ckpt_13\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.8826 - accuracy: 0.7189\n",
            "Epoch 14/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8340 - accuracy: 0.7341\n",
            "Epoch 14: saving model to ./training_checkpoints/ckpt_14\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.8340 - accuracy: 0.7341\n",
            "Epoch 15/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7923 - accuracy: 0.7468\n",
            "Epoch 15: saving model to ./training_checkpoints/ckpt_15\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.7923 - accuracy: 0.7468\n",
            "Epoch 16/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7592 - accuracy: 0.7568\n",
            "Epoch 16: saving model to ./training_checkpoints/ckpt_16\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.7592 - accuracy: 0.7568\n",
            "Epoch 17/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7301 - accuracy: 0.7653\n",
            "Epoch 17: saving model to ./training_checkpoints/ckpt_17\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.7301 - accuracy: 0.7653\n",
            "Epoch 18/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.7714\n",
            "Epoch 18: saving model to ./training_checkpoints/ckpt_18\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.7085 - accuracy: 0.7714\n",
            "Epoch 19/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.7757\n",
            "Epoch 19: saving model to ./training_checkpoints/ckpt_19\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.6920 - accuracy: 0.7757\n",
            "Epoch 20/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.7788\n",
            "Epoch 20: saving model to ./training_checkpoints/ckpt_20\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.6798 - accuracy: 0.7788\n",
            "Epoch 21/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.7811\n",
            "Epoch 21: saving model to ./training_checkpoints/ckpt_21\n",
            "345/345 [==============================] - 13s 38ms/step - loss: 0.6702 - accuracy: 0.7811\n",
            "Epoch 22/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6641 - accuracy: 0.7824\n",
            "Epoch 22: saving model to ./training_checkpoints/ckpt_22\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.6641 - accuracy: 0.7824\n",
            "Epoch 23/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.7834\n",
            "Epoch 23: saving model to ./training_checkpoints/ckpt_23\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.6589 - accuracy: 0.7834\n",
            "Epoch 24/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.7830\n",
            "Epoch 24: saving model to ./training_checkpoints/ckpt_24\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 0.6569 - accuracy: 0.7830\n",
            "Epoch 25/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.7830\n",
            "Epoch 25: saving model to ./training_checkpoints/ckpt_25\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 0.6564 - accuracy: 0.7830\n",
            "Epoch 26/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6586 - accuracy: 0.7820\n",
            "Epoch 26: saving model to ./training_checkpoints/ckpt_26\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 0.6586 - accuracy: 0.7820\n",
            "Epoch 27/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6606 - accuracy: 0.7805\n",
            "Epoch 27: saving model to ./training_checkpoints/ckpt_27\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 0.6606 - accuracy: 0.7805\n",
            "Epoch 28/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6616 - accuracy: 0.7799\n",
            "Epoch 28: saving model to ./training_checkpoints/ckpt_28\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 0.6616 - accuracy: 0.7799\n",
            "Epoch 29/30\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.7780\n",
            "Epoch 29: saving model to ./training_checkpoints/ckpt_29\n",
            "345/345 [==============================] - 12s 35ms/step - loss: 0.6672 - accuracy: 0.7780\n",
            "Epoch 30/30\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.7768\n",
            "Epoch 30: saving model to ./training_checkpoints/ckpt_30\n",
            "345/345 [==============================] - 12s 34ms/step - loss: 0.6708 - accuracy: 0.7767\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=30, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(10000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCYAjVaI1OLG",
        "outputId": "05b3f8ac-63fd-484d-97e3-9fb210e81feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Thou wast not, but your father Capulet: 'tis gone a gentleman;\n",
            "Which to remained by the noise of it?\n",
            "\n",
            "SICINIUS:\n",
            "This is strange of him; how seemed you?\n",
            "\n",
            "TRANIO:\n",
            "Mistress, we will cry it out my fitting and no good.\n",
            "\n",
            "HORTENSIO:\n",
            "Petruchio, since my heart\n",
            "I have a ripe: lust you in justice, if my life\n",
            "Scapting our ancient gracious queen,\n",
            "A most shame in queshio.'\n",
            "Crewas, brother, if thou hast advented\n",
            "Our partial 'er, knee with you;\n",
            "Since when we were tricks, and merry waves! Bolan! pray,\n",
            "Doth chois me, and I am now given me merry:\n",
            "I am no a gentleman's face; I am\n",
            "courted and pry my carry within.\n",
            "\n",
            "Sendat add him, he had something near me yet,\n",
            "Sir Viechous which honest malice or\n",
            "arisonable burst, or who loved his love\n",
            "To make again seems without innocence, which should\n",
            "not scorn for fault. To call thee seeath\n",
            "As now incessage there,\n",
            "Without come and Pertiss, and now away so far\n",
            "To look and Norfolk, Warwick, what a stranger in\n",
            "the nobility of toman torment?\n",
            "It is a good dinner-piery enes.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "'Twas I wonderful fata, she shall: and her are thou know'st, awaked, a\n",
            "bear it in the presence makes upon her: thou misutued your\n",
            "canother where my sir Bisadvented from me,\n",
            "In sufficient of old precition,\n",
            "Dakes me mine own youngest and ourselves, we arget\n",
            "Thy brother by arturies to move\n",
            "As now a simple that I fear,\n",
            "The matter beats no time that know his daughter's barn\n",
            "May be whose weakness past myself.\n",
            "\n",
            "ANGELO:\n",
            "Well said, make an envious and a quaster\n",
            "As I say, by any mine: yet I can here.\n",
            "What! God from Oxford! what mine, where I am and\n",
            "As by a child's keeping?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "In die our army eye so partly know you what you are.\n",
            "\n",
            "Pedant:\n",
            "Sir, take thou the wasing fair Bianca,' and\n",
            "'Seak go, leave me in my tale.\n",
            "\n",
            "KING HENRY VI:\n",
            "Why, then, faith, sweet remove;\n",
            "Let them and further thing I bid; you know 'twas hang\n",
            "They put before your brother, but this life bewipp'd\n",
            "With any lung all of us kind and happy days,\n",
            "And wakes a little thankinds of neck. Is't not melts?\n",
            "It is a respected woman, he his life,\n",
            "My oath as thou remember'st ungone that\n",
            "Camulet; and have life betimes;\n",
            "For he undernew'd with grief wouldst discured,\n",
            "Were strange fives be their beafured acting table:\n",
            "We will be well without gently now gone,\n",
            "Being one thoughts shall be medly with thee.\n",
            "\n",
            "HORTENSIO:\n",
            "Sirrah, come, not yours and our task is in mine intent\n",
            "The monument of the devil's crob.\n",
            "And for these creeting, which should know thou art so reflewish'd?\n",
            "I trimble you, fond wrong'd, for my mistress,\n",
            "What unstill we call in thy bodies thir\n",
            "thou drown the common earth some speech I diddle deat?\n",
            "\n",
            "PAULINA:\n",
            "I swear.\n",
            "\n",
            "ANTONIO:\n",
            "Henry not a slave, sir.\n",
            "\n",
            "LUCIO:\n",
            "Most holdine son, we trouble upon my absence haze\n",
            "The horse effect of his most wrong.\n",
            "\n",
            "KING LEWIS XI:\n",
            "That she, the manors, who should say, My lusty Citizens:\n",
            "Woes him; or else he both provide me\n",
            "To him and Camillo with shame to kiss\n",
            "To greet your lordship dren; and obey, blasping age,\n",
            "Baying in such particiliable.\n",
            "\n",
            "PETRUCHIO:\n",
            "Content thyself: take heaven be as breathe and will done so.\n",
            "Away! you frownd with this my brother die.\n",
            "\n",
            "ISABELLA:\n",
            "All things in forely put\n",
            "to death. Did you not bid me leave your bosom,\n",
            "And I\n",
            "know not the safe, which pray'd-all power now,\n",
            "Scalceful oranous tentlenes to\n",
            "Angelo! How dot promise this man as\n",
            "we know, it is my hast gone to Warwick; but\n",
            "We see 'thou mayst be brought doth ring.\n",
            "\n",
            "HASTINGS:\n",
            "The poor sure Isabel.\n",
            "\n",
            "LUCIO:\n",
            "\n",
            "VINCENTIO:\n",
            "Ay, madam, Hortensio, lords, man: all obey his countenances. I am proof.\n",
            "\n",
            "LUCIO:\n",
            "Do not be seen to be unto their graves.\n",
            "\n",
            "ANGELO:\n",
            "By any of this, that's our battage.\n",
            "Say to the Capule?\n",
            "Is he not weak and weep: the offer is,\n",
            "And the ranks of the dukes will hence be of her:\n",
            "Can quest divine years or no:\n",
            "Carry his goldant jointys me for them?\n",
            "\n",
            "ARIEL:\n",
            "Sir, in my request\n",
            "Is not to saunt in no ancient with this forgial.\n",
            "\n",
            "ISABELLA:\n",
            "God save you, Signior Brother kindly withal.\n",
            "\n",
            "TRANIO:\n",
            "I'll be your father. Taster and before.\n",
            "\n",
            "BIONDES:\n",
            "Look, no, I see there is not gives good sister.\n",
            "\n",
            "LUCENTIO:\n",
            "Love wa' in a twine of this.\n",
            "\n",
            "Provost:\n",
            "Ay. Why, upon me, sir; but I can tell you.\n",
            "\n",
            "MARCIUS:\n",
            "You shall not stir my state of act or will\n",
            "That if you do with it confesses. The manner\n",
            "of her wrong.\n",
            "I will give tham, she begin on Lucentio.\n",
            "\n",
            "LUCENTIO:\n",
            "Here, for all the rest:\n",
            "Heren upon me, and our council here.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "\n",
            "BAPTISTA:\n",
            "What, my good friar? who, wilt thou knew my brother's ajes?\n",
            "\n",
            "POMPEY:\n",
            "Mistress, we hear gentle words.\n",
            "\n",
            "ESCALUS:\n",
            "What, are you as deny?\n",
            "\n",
            "LUCENTIO:\n",
            "I talk not, I can tell you; know you art while: I\n",
            "have heard stooping thoughts, and thus much scarsed your brother,\n",
            "'Twixt thou he in my barren effect.\n",
            "\n",
            "PAULINA:\n",
            "Take him to the dark.\n",
            "\n",
            "AETINIO:\n",
            "'Tis the wild waters attend on the way.\n",
            "\n",
            "CAPULET:\n",
            "Send you have the draw.\n",
            "\n",
            "CAPULET:\n",
            "Ay, sir, your welcomes!\n",
            "\n",
            "BIANCA:\n",
            "Pardon; I am prepared how to undertake.\n",
            "\n",
            "SICINIUS:\n",
            "Sir, I thank you.\n",
            "\n",
            "First Gentleman:\n",
            "Tranio, grief to the which no less.\n",
            "\n",
            "GREMIO:\n",
            "Thou hast in resolate, of this isle,\n",
            "Showift I am called my knee but instruct me,\n",
            "Dismantly thankfully made inchinable:\n",
            "I love a build, a long make her spirit than the\n",
            "intents be talking, take it not a straw.\n",
            "\n",
            "BIANCA:\n",
            "It was so frair by words. I am come to know\n",
            "What, with your hiddle rich, that I say, and bring\n",
            "forth mine armour with me: I will but assured Her circh\n",
            "On this good lady, and these your fortunes\n",
            "To thee up the service, take you to dishonour\n",
            "You will gaze all age.\n",
            "\n",
            "MARIANA:\n",
            "Not her, my lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Dear sir, and he are at this image to win my\n",
            "boot in thinking on the war; be at the foe, sir.\n",
            "\n",
            "BAPTISTA:\n",
            "Basemble not confinment to give him the regle at my\n",
            "brother; and, I being 'muted, daughters, breath with your elder;\n",
            "and first betimes that keep within. Consort! with him! I am so much\n",
            "To win his country, -then in love will remain\n",
            "Of what thou either made to all this?\n",
            "\n",
            "BIANCA:\n",
            "I am your servants what is death doth bring him for the lane\n",
            "Where the fair Biands more than my alike.\n",
            "\n",
            "ROMEO:\n",
            "Thou what's fault of me,--and we proclaim'd.\n",
            "\n",
            "KATHARINA:\n",
            "I bid this be crosple,\n",
            "though thou mightst cap runa lies go;\n",
            "But whether he dare the end best was lawken'd in\n",
            "fair and night: Bianca speak a while, so sooth the wreck\n",
            "To help him hide against the will, good father!\n",
            "Give her hence! in the consul, and your daughter sir,\n",
            "That he should say 'twas done:\n",
            "But must I see if Claudio tyrant;\n",
            "And do you noted coat, in the whole maid\n",
            "In councils whose children of a while:\n",
            "Did I sweat down in forten, I have known better\n",
            "By anging, whilst I blasp it, Lucentio.\n",
            "\n",
            "LUCENTIO:\n",
            "Widow, by my father's rocks? What, not a pox\n",
            "to o'er and obice of sense in winds\n",
            "Thy unlegs and more cease to make the ring\n",
            "As you should say 'tis power? She shall\n",
            "Without supporrediers wives, mant! why would please the words\n",
            "What of your own desires. Fare you well.\n",
            "\n",
            "ANTONIO:\n",
            "You wrong hours, belitaber daughter.\n",
            "\n",
            "GREMIO:\n",
            "Amen, a peneout breath, but your knee rangs; set it in the matter.\n",
            "\n",
            "GREMIO:\n",
            "Dare not a pair in holy, sir, and not love with you,\n",
            "For then our lives at only mates.\n",
            "What are they do attend me?\n",
            "\n",
            "MARIANA:\n",
            "Not your wife! Can my nature in noth such\n",
            "shames it so: but I will all resolve to yourself\n",
            "And then have left born with curious,\n",
            "Thou stern me to your former match.\n",
            "\n",
            "Provost:\n",
            "A lab, their souls,\n",
            "Was that you to't.\n",
            "\n",
            "POLIXENES:\n",
            "Is this groan amits the creater?\n",
            "Thou shalt show'd my loyal servant; where,\n",
            "I met your dotes; I am comfort to a well-igning gown;\n",
            "And with a side hath been banished make's peace,\n",
            "And loar him hide the ruptial and the\n",
            "same I woe it to pardon for my sea-sway;\n",
            "And now all with a priend.\n",
            "\n",
            "KATHARINA:\n",
            "No reservy thoo i' the head of Gaunt.\n",
            "\n",
            "BIANCA:\n",
            "Hear Perantateous and wide and Daughs.\n",
            "\n",
            "LARIONA:\n",
            "O this way, it the town; I'll assure her;\n",
            "Liep have no matter\n",
            "Doth with the head of Gloucester.\n",
            "\n",
            "ANTIGONUS:\n",
            "If it be so, sir, a device, and beat you to yourself:\n",
            "Yet he will shame us wind one in him.\n",
            "\n",
            "ANTONIO:\n",
            "Who shall believe me? O let him gold thee at the last,\n",
            "Even then will draint the heir of Gent!\n",
            "\n",
            "LADY ANNE:\n",
            "'Widou princise?\n",
            "\n",
            "FROTH:\n",
            "All houses in a foul word drew that quench it.\n",
            "\n",
            "Clown:\n",
            "Not, if you could sin, who know their own humble weeds!\n",
            "What, in the blood, mean to her?\n",
            "\n",
            "LUCENTIO:\n",
            "Alack, poor soul!\n",
            "\n",
            "KATHARINA:\n",
            "Patience, I pray you.\n",
            "\n",
            "First Senator:\n",
            "Now is your strength, dryam'st, is a bracelet kind an unman\n",
            "kneel for a kindred; for you are quietes the old master,\n",
            "That I was bear a partake to the master,\n",
            "And, as I am, it do attlight\n",
            "And finds more resolves. But, as you are, master:\n",
            "The Volsces are hurried mine above his, mantle, he;\n",
            "Making a tafter of the dukedom, unhereaft.\n",
            "Not since your words will hold you to 't. Brave me,\n",
            "And ravour'd till we could for his desirity.\n",
            "\n",
            "WARWICK:\n",
            "And but at laught as deep as he is mean to call\n",
            "I Pity thy mirth. The ifle infection\n",
            "show my good father, I am able to be a pitiful\n",
            "coach way, to when you seem'd off untalk\n",
            "Her kinsmen and rebellion and grants\n",
            "this isle play the queen'd in this centation be\n",
            "penite; tyll me them suffer-crown. Heavens, my hearts!\n",
            "\n",
            "LEONTES:\n",
            "WhAt!\n",
            "\n",
            "LUCENTIO:\n",
            "Ay, then I'll speak all.\n",
            "Thus profish bare theed now incensest thou art,\n",
            "He waked him as it will know his tribune.\n",
            "What, in the minstrels, gidest thou thy love?\n",
            "\n",
            "PETRUCHIO:\n",
            "Pardon, eat!\n",
            "\n",
            "ESCALUS:\n",
            "Away.\n",
            "\n",
            "Gaoler:\n",
            "I am soon\n",
            "As all the roof to tain: if you be so\n",
            "confess, I have watch'd on foot at homa,\n",
            "That she was common fears themselves, such aspempt,\n",
            "Is through the meltiful choice in Camillo was\n",
            "And no other way.\n",
            "\n",
            "LUCENTIO:\n",
            "Now, my spirits loon.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "It may be done.\n",
            "\n",
            "PROSPERO:\n",
            "Thou that is not;\n",
            "No hearing that were rather she were love\n",
            "To Richmond that the outside of your all.\n",
            "\n",
            "Third Watch and Master Frank; when the king\n",
            "shall be here with many longest thou art.\n",
            "\n",
            "ANGELO:\n",
            "That are marvellous as the most precious boon.\n",
            "\n",
            "LUCENTIO:\n",
            "'Tis nothing.\n",
            "\n",
            "DIO:\n",
            "Thou know'st, was with a thing encounter\n",
            "A league or air. At laught,\n",
            "and let us hear the toward then.\n",
            "\n",
            "HORTENSIO:\n",
            "And spit what you are quick. His and prague and more sports\n",
            "Shall rinion to die this master;  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 23.33732509613037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9jwZ9ryTA2oB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNIF9TRTOb7fGd0mRoFA2z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}